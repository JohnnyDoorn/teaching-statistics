# ANCOVA

```{r, echo=FALSE}
# Clear memory
rm(list=ls())

if(!"ggplot2" %in% installed.packages()) { install.packages("ggplot2") }
library("ggplot2")

set.seed(1976)

if(!"DT" %in% installed.packages()) { install.packages("DT") }
library("DT")
```

## ANCOVA {.section}

Analysis of covariance (ANCOVA) is a general linear model which blends ANOVA and regression. ANCOVA evaluates whether population means of a dependent variable (DV) are equal across levels of a categorical independent variable (IV) often called a treatment, while statistically controlling for the effects of other continuous variables that are not of primary interest, known as covariates (CV).

[WIKIPEDIA](https://en.wikipedia.org/wiki/Analysis_of_covariance)

## ANCOVA

Determine main effect while correcting for covariate

* 1 dependent variable
* 1 or more independent variables
* 1 or more covariates

A covariate is a variable that can be a confounding variable biasing your results. By adding a covariate, we reduce error/residual in the model.

## Assumptions

* Same as ANOVA
* Independence of the covariate and treatment effect ยง13.4.1.
    * No difference on ANOVA with covar and independent variable
    * Matching experimental groups on the covariate
* Homogeneity of regression slopes ยง13.4.2.
    * Visual: scatterplot dep var * covar per condition
    * Testing: interaction indep. var * covar

## Independence of the covariate and treatment effect

<img src="FieldCovWarning.png" style="width:40%;"/>

## Data example

We want to test the difference in national extraversion but want to also account for openness to experience.

* Dependent variable: Extraversion
* Independent variabele: Nationality
    + Dutch
    + German
    + Belgian
* Covariate: Openness to experience

## Simulate data

```{r, echo=TRUE}
# Simulate data
n <- 20
k <- 3
nationality       <- round(runif(n,1,k),0)
nationality <- factor(nationality)
levels(nationality) <- c("Dutch", "German", "Belgian")
mu.covar    <- 8
sigma.covar <- 1
openness       <- round(rnorm(n,mu.covar,sigma.covar),2)

# Create dummy variables
dummy.1 <- ifelse(nationality == "German", 1, 0)
dummy.2 <- ifelse(nationality == "Belgian", 1, 0)

# Set parameters
b.0 <- 15 # initial value for group 1
b.1 <- 3  # difference between group 1 and 2
b.2 <- 4  # difference between group 1 and 3
b.3 <- 3  # Weight for covariate

# Create error
error <- rnorm(n,0,1)
```

## Define the model {.subsection}

${extraversion} = {model} + {error}$

${model} = {independent} + {covariate} = {nationality} + {openness}$

Formal model

$y = b_0 + b_1 {dummy}_1 + b_2 {dummy}_2 + b_3 covar$


```{r, echo=TRUE}
# Define model
extraversion <- b.0 + b.1 * dummy.1 + b.2 * dummy.2 + b.3 * openness + error
```

## Dummies {.smallest}

```{r, echo=FALSE}
extraversion <- round(extraversion,2)
error <- round(error,2)

n <- 1:length(extraversion)

dummies <- data.frame(nationality, b.0, b.1, dummy.1, b.2, dummy.2, b.3, openness, error, extraversion)

datatable(dummies, options = list(searching = FALSE, scrollY = 435, paging = FALSE, info = FALSE))
```

## The data {.smaller}

```{r, echo=FALSE}
# put data in data frame
data <- data.frame(nationality, openness, extraversion)

# Order by group
data <- data[order(as.numeric(data$nationality)),]
data <- cbind(n, data)
# Write data for use in SPSS
write.csv(data, "ANCOVA_Shar.csv", row.names=FALSE)

datatable(data, 
          extensions = 'Buttons',
          options    = list(searching = FALSE, 
                            scrollY   = 300, 
                            paging    = F, 
                            info      = F,
                            dom       = 'Bfrtip',
                            buttons   = c('csv')),
)
```

## Observed group means {.subsection}

```{r, echo=TRUE}
aggregate(extraversion ~ nationality, data, mean)
```

## Model fit without covariate

What are the beta coefficients when we fit a model that only has "nationality" as a predictor variable?

```{r, echo=TRUE}
fit.group <- lm(extraversion ~ nationality, data); fit.group
fit.group$coefficients[2:3] + fit.group$coefficients[1]
```

${Dutch} = `r  fit.group$coefficients[1]` \> {German} = `r fit.group$coefficients[2] + fit.group$coefficients[1]` \> {Belgian} = `r fit.group$coefficients[3] + fit.group$coefficients[1]`$


## Model fit with only covar {.subsection}

What are the beta coefficients when we fit a model that only has the covariate as predictor variable?

```{r, echo=TRUE}
fit.covar <- lm(extraversion ~ openness, data)
fit.covar
```

## Model fit with all predictor variables (factor + covariate)

```{r, echo=TRUE}
fit <- lm(extraversion ~  nationality + openness, data); fit
fit$coefficients[2:3] + fit$coefficients[1]
```

```{r, echo=FALSE}
fit$coefficients <- round(fit$coefficients, 2)
```

${Dutch} = `r  fit$coefficients[1]` \> {German} = `r fit$coefficients[2] + fit$coefficients[1]` \> {Belgian} = `r fit$coefficients[3] + fit$coefficients[1]`$

## So what do we predict for each participant??

For a German with a score of 8 on Openness:

```{r, echo=TRUE}
fit <- lm(extraversion ~ nationality + openness, data); fit$coefficients

unname(fit$coefficients[1] + 1 * fit$coefficients[2] + 0 * fit$coefficients[3] + 
  8 * fit$coefficients[4])
```
How about a Belgian with 6 Openness?

## Total variance {.subsection}

What is the total variance?

${MS}_{total} = s^2_{extraversion} = \frac{{SS}_{extraversion}}{{df}_{extraversion}}$

```{r, echo=TRUE}
ms.t <- var(data$extraversion); ms.t
ss.t <- var(data$extraversion) * (length(data$extraversion) - 1); ss.t
```

## The data

```{r, echo=FALSE}
# Add grand mean to data frame
data$grand.mean <- mean(data$extraversion)

datatable(data, options = list(searching = FALSE, scrollY = 415, paging = F, info = F))
```

## Total variance visual {.subsection}

```{r, echo=FALSE}
plot <- ggplot(data, aes(x=n, y=extraversion)) + geom_point(shape=1) +
  geom_hline(yintercept=mean(extraversion)) +
  geom_segment(aes(x = n, y = grand.mean, xend = n, yend = extraversion)) +
  ggtitle("Total variance")
plot
```

## Model variance group {.smaller}

The model variance consists of two parts. One for the independent variable and one for the covariate. Lets first look at the independent variable.

```{r, echo=FALSE}
data$model.group <- round(fit.group$fitted.values, 2)

datatable(data, options = list(searching = FALSE, scrollY = 315, paging = F, info = F))
```

## Model variance group visual {.subsection}

```{r, echo=FALSE}
plot + geom_segment(aes(x = n, y = grand.mean, xend = n, yend = data$model.group, colour = nationality)) +
  ggtitle("Only group variance")
```

## Model variance covariate visual {.subsection}

```{r, echo=FALSE}
data$model.covar <- round(fit.covar$fitted.values,2)
plot + geom_segment(aes(x = n, y = grand.mean, xend = n, yend = data$model.covar, colour = nationality)) +
  ggtitle("Only covariate variance")
```

## Model variance group and covariate {.smaller}

```{r, echo=FALSE}
data$model       <- round(fit$fitted.values, 2)

datatable(data, options = list(searching = FALSE, scrollY = 415, paging = F, info = F))
```

## Model variance group and covariate visual {.subsection}

```{r, echo=FALSE}
plot + geom_segment(aes(x = n, y = grand.mean, xend = n, yend = data$model, colour = nationality)) -> plot

plot + ggtitle("Both group and covariate variance")
```

## Error variance with covariate {.subsection}

```{r, echo=FALSE}
plot + geom_segment(aes(x      = n-.1, 
                        y      = extraversion, 
                        xend   = n-.1, 
                        yend   = data$model, 
                        colour = "purple")) + 
  ggtitle("Error variance")
```

## Sums of squares {.subsection}

```{r, echo=TRUE}
SS.model <- with(data, sum((model - grand.mean)^2))
SS.error <- with(data, sum((extraversion - model)^2))

# Sums of squares for individual effects
SS.model.group <- with(data, sum((model.group - grand.mean)^2))
SS.model.covar <- with(data, sum((model.covar - grand.mean)^2))

SS.covar <- SS.model - SS.model.group; SS.covar ## SS.covar corrected for group
SS.group <- SS.model - SS.model.covar; SS.group ## SS.group corrected for covar
```

## F-ratio {.subsection}

$F = \frac{{MS}_{model}}{{MS}_{error}} = \frac{{SIGNAL}}{{NOISE}}$

```{r, echo=TRUE}
n <- 20
k <- 3
df.model <- k - 1
df.error <- n - k - 1

MS.model <- SS.group / df.model
MS.error <- SS.error / df.error

fStat <- MS.model / MS.error
fStat
```

## $P$-value

```{r, echo=TRUE}
library("visualize")
visualize.f(fStat, df.model, df.error, section = "upper") 
```

## Alpha & Power
Power becomes quite abstract when we increase the complexity (i.e., number of predictors) of our models. We can make an F-distribution that symbolizes the alternative distribution by shifting the distribution more to the right (although the interpretability becomes pretty murky..)
```{r, echo=FALSE}
fValues <- seq(0, 30, .01)

plot(fValues, df(fValues, df.model, df.error), type = "l", ylab="density", main = "H0 and HA F-distribution")

critical.value = qf(.95, df.model, df.error)

critical.range = seq(critical.value, 30, .01)

polygon(c(critical.range,rev(critical.range)), 
        c(critical.range*0, rev(df(critical.range, df.model, df.error, ncp = 15))), col = "green")

lines(fValues, df(fValues, df.model, df.error, ncp = 15))

polygon(c(critical.range,rev(critical.range)), 
        c(critical.range*0, rev(df(critical.range, df.model, df.error))), col = "red")
```


## Adjusted/marginal means

Marginal means are estimated group means, while keeping the covariate equal across the groups

These are then the means that are used for follow-up tests, such as contrasts and post hoc tests

See also [this blogpost](https://jasp-stats.org/2020/04/14/the-wonderful-world-of-marginal-means/) I wrote a while ago


## Adjusted/marginal means

```{r, echo=TRUE}
# Add dummy variables
data$dummy.1 <- ifelse(data$nationality == "German", 1, 0)
data$dummy.2 <- ifelse(data$nationality == "Belgian", 1, 0)

# b coefficients
b.cov <- fit$coefficients["openness"];          b.int = fit$coefficients["(Intercept)"]
b.2   <- fit$coefficients["nationalityGerman"]; b.3   = fit$coefficients["nationalityBelgian"]

# Adjustment factor for the means of the independent variable
data$mean.adj <- with(data, b.int + b.cov * mean(openness) + b.2 * dummy.1 + b.3 * dummy.2)

aggregate(mean.adj ~ nationality, data, mean)

aggregate(extraversion ~ nationality, data, mean)
```




