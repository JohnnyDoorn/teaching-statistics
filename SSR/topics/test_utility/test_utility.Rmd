# Test Utility

<!-- Allow color highlighting in mathjax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
</script>

## What is Test Utility {.subsection}

Test Utility literally refers to using a test as a utility, as a tool. And in our context we mean using tests as a toal for selection.

### Costs and benefits

* monetary
* non-monetary

The psychometric properties of the test determine the relationship between costs and benefits.

These properties can be empirically tested. We will show you the reasoning process in this lecture.

## Predictive / Criterion Validity {.subsection}

Often we want to predict based on test scores how an individual will perform at a later time.

* The thing we want to predict is called the **criterion**
    * Example: good employees or good students
* The test we use to predict is obviously called the **predictor**

The predictive validity is defined as the correlation between the **predictor** / test score and the **criterion**.

**NOTE:** This is no different than the $R$ in regular regression analysis; the correlation between the outcome and the model.

## {data-background=../../../topics/test_utility/tile.jpg data-background-size=contain .flexbox .vcenter}

<p style="color:darkblue; font-size:200%; text-align: center;">With a correlation of zero,<br>selection is useless</p> <!-- [Dutch Tile](https://www.flickr.com/photos/paulussie/15582506882) -->

## Cut-off scores

Based on our criterion and predictor we need to determine:

> 1. When we trully know someone is competent.
> 2. At what predictor score we want to select someone.

That means setting a:

> * Cut-off for the criterion (Base Rate)
> * Cut-off for the predictor (Selection Ratio)

## Utility (interactive)

```{r, child="utility_interactive_scatterplot.Rmd"}
```

## CASE STUDY:

Admission test (NL: selectie aan de poort)

* Test week data from UvA Psychology students
    * Motivation
    * Study results
* The data was gathered before we actually had admission tests (all students where admitted).
* Because of this, we can determine the effectiveness of a supposed admissions procedure.
* We can calculate how much better our results would be if we had actually selected.
* This comparison will show us how much there is to gain and the price we have to pay

```{r, fig.asp=1/3, echo=FALSE}
load("data.Rdata")
names(dat) <- c("Motivation", "StudyResults")

avg.mot <- mean(dat$Motivation)
pass.mark <- 6
correlation <- cor(dat)[1,2]

cross.tabs <- table(data.frame(dat$StudyResults > pass.mark,
                               dat$Motivation > avg.mot))

TP <- cross.tabs[2,2]
FN <- cross.tabs[2,1]
FP <- cross.tabs[1,2]
TN <- cross.tabs[1,1]
N <- sum(cross.tabs)


layout(matrix(1:3, 1, 3))
hist(dat$Motivation, col = "orange", xlab = "z-scores", main = "Motivation")
abline(v=avg.mot, lwd = 2)
hist(dat$StudyResults, col = "orange", xlab = "average grades", main = "Study Results")
abline(v=pass.mark, lwd = 2)
plot(dat, col = "orange", ylab = "average grades", main = "Correlation")
expand = 2
text(avg.mot + expand, pass.mark + expand, TP, cex = 2)
text(avg.mot - expand, pass.mark + expand, FN, cex = 2)
text(avg.mot - expand, pass.mark - expand, TN, cex = 2)
text(avg.mot + expand, pass.mark - expand, FP, cex = 2)
abline(h=pass.mark, v=avg.mot, lwd = 2)
```

* Average Motivation: `r round(avg.mot,3)`
* Pass mark: 6
* Correlation: `r round(correlation,3)`

## Hit Rate {.subsection}

<table style="width: 150px; height:150px; text-align:center; float:right;">
<tr>
<td style="background-color:red;   width: 50px; color:white;">FN<br><span style="font-size:60%;">`r FN`</span></td>
<td style="background-color:green; width: 50px; color:white;"">TP<br><span style="font-size:60%;">`r TP`</span></td>
</tr>
<tr>
<td style="background-color:green; width: 50px; color:white;">TN<br><span style="font-size:60%;">`r TN`</span></td>
<td style="background-color:red;   width: 50px; color:white;">FP<br><span style="font-size:60%;">`r FP`</span></td>
</tr>
</table>

Percentage of correct conclusions.

$$\definecolor{green}{RGB}{0,128,0}
\text{Hit Rate} = \frac{{\color{green}\text{TP}} + \color{green}\text{TN}}{N}$$

<br><br>

$$\frac{`r TP` + `r TN`}{`r N`} = `r HR = round( (TP+TN)/N, 2); HR`$$

## Base Rate {.subsection}

<table style="width: 150px; height:150px; text-align:center; float:right;">
<tr>
<td style="background-color:red;   width: 50px; color:white;">FN<br><span style="font-size:60%;">`r FN`</span></td>
<td style="background-color:green; width: 50px; color:white;"">TP<br><span style="font-size:60%;">`r TP`</span></td>
</tr>
<tr>
<td style="background-color:green; width: 50px; color:white;">TN<br><span style="font-size:60%;">`r TN`</span></td>
<td style="background-color:red;   width: 50px; color:white;">FP<br><span style="font-size:60%;">`r FP`</span></td>
</tr>
</table>

Percentage of correct conclusions when not selecting.

$$\definecolor{red}{RGB}{255,0,0}
\text{Base Rate} = \frac{{\color{green}\text{TP}} + \color{red}\text{FN}}{N}$$

<br><br>

$$\frac{`r TP` + `r FN`}{`r N`} = `r BR = round( (TP+FN)/N, 2); BR`$$

## Hit Rate - Base Rate

To determine the benefit of selection, we need to know what the hit rate is compared to the base rate.

$$\text{Hit Rate} - \text{Base Rate} = \text{Benefit}$$

<br><br>

$$`r HR` - `r BR` = `r HR - BR`$$

## Sensitivity {.subsection}

<table style="width: 150px; height:150px; text-align:center; float:right;">
<tr>
<td style="background-color:red;   width: 50px; color:white;">FN<br><span style="font-size:60%;">`r FN`</span></td>
<td style="background-color:green; width: 50px; color:white;"">TP<br><span style="font-size:60%;">`r TP`</span></td>
</tr>
<tr>
<td style="background-color:green; width: 50px; color:white;">TN<br><span style="font-size:60%;">`r TN`</span></td>
<td style="background-color:red;   width: 50px; color:white;">FP<br><span style="font-size:60%;">`r FP`</span></td>
</tr>
</table>

We can determine the efficiency of selection by calculating the sensitivity and specificity of a test.

**Sensitivity:** Percentage of eligible candidates that will be selected.

$$\text{Sensitivity} = \frac{\color{green}\text{TP}}{{\color{red}\text{FN}} + \color{green}\text{TP}}$$

<br><br>

$$\frac{`r TP`}{`r FN` + `r TP`} = `r sen = round( TP/(FN+TP), 2); sen`$$

## {data-background=../../../topics/test_utility/tile.jpg data-background-size=contain .flexbox .vcenter}

<p style="color:darkblue; font-size:200%; text-align: center;">The lower the sensitivity<br>The more frustrated<br>parents and students</p>

## Specificity {.subsection}

<table style="width: 150px; height:150px; text-align:center; float:right;">
<tr>
<td style="background-color:red;   width: 50px; color:white;">FN<br><span style="font-size:60%;">`r FN`</span></td>
<td style="background-color:green; width: 50px; color:white;"">TP<br><span style="font-size:60%;">`r TP`</span></td>
</tr>
<tr>
<td style="background-color:green; width: 50px; color:white;">TN<br><span style="font-size:60%;">`r TN`</span></td>
<td style="background-color:red;   width: 50px; color:white;">FP<br><span style="font-size:60%;">`r FP`</span></td>
</tr>
</table>

**Specificity:** Percentage of inapt candidates that will be rejected.

$$\text{Specificity} = \frac{\color{green}\text{TN}}{{\color{green}\text{TN}} + \color{red}\text{FP}}$$

<br><br>

$$\frac{`r TN`}{`r TN` + `r FP`} = `r spe = round( TN/(TN+FP), 2); spe`$$

## Steps to determine efficiency

1. Select predictor and criterion
2. Calculate the correlation in an unselected sample
3. Determine the efficiency based on possible cut-off scores

## {data-background=../../../topics/test_utility/tile.jpg data-background-size=contain .flexbox .vcenter}

<p style="color:darkblue; font-size:200%; text-align: center;">Only if you select everyone<br>you can determine<br>the quality of the procedure</p>

## Taylor-Russell Tables {.subsection}

So, what if you do not have the resources to conduct empirical research?

In that case, you can resort to using Taylor-Russell tables, hhich provide estimates of the percentage of eligible candidates of those selected.

* TABLE: Base Rate
* Y-AXIS: Predictive validity
* X-AXIS: Selection ratio
* CELLS: Proportion satisfactory among those selected = $\frac{\color{green}\text{TP}}{{\color{green}\text{TP}} + \color{red}\text{FP}}$ 

<div style="font-size:50%;">
[Taylor, H, and Russell, J. “The Relationship of Validity Coefficients to the Practical Effectiveness of Tests in Selection: Discussion and Tables.” Journal of Applied Psychology 23 (1939): n. pag. Web.](https://lib.uva.nl/permalink/31UKB_UAM1_INST/h37vvk/proquest1290354749)
</div>

<div style="font-size:30%;">

```{r, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
# install.packages("readxl")
library("readxl")
library("DT")
tr.table <- read_excel("TaylorRusselTable.xlsx")
datatable(tr.table, extensions = 'FixedColumns', rownames = F,
  options = list(
    pageLength = 21,
    dom = 't',
    scrollX = TRUE,
    fixedColumns = TRUE
  ) )
```

</div>

## {.flexbox .vcenter}

<img style="width:80%;" src="../../../topics/test_utility/TaylorRussell.png">

## Influential factors {.subsection}

The two factors influencing the cell values "The proportion satisfactory among those selected" are:

<img style="width:60%; float:right;" src="../../../topics/test_utility/TR_colors.png">

* Predictive validity
* Selection ratio

## Increase efficiency {.subsection}

So, there are two ways to increase efficiency

* Increase predictive validity
* Use more extreme selection ratio

```{r, fig.asp=1/3, echo=FALSE, fig.align="center"}
set.seed(12345)

x = rnorm(100)
y.1 = x + rnorm(100, 0, .7)
y.2 = x + rnorm(100, 0, 2)
y.3 = x + rnorm(100, 0, 3)

layout(matrix(1:3, 1, 3))
plot(x, y.1, col = "orange", ylab = "average grades", xlab = "motivation", main = "Correlation", xaxt="n", yaxt="n")
plot(x, y.2, col = "orange", ylab = "", xlab = "motivation", main = "Correlation", xaxt="n", yaxt="n")
plot(x, y.3, col = "orange", ylab = "", xlab = "motivation", main = "Correlation", xaxt="n", yaxt="n")
```

## Threats to validity {.subsection}

Criterion validity is threatened by all factors that reduce the relation between predictor and criterion.

* Unreliable tests: noise reduces the relation.
* Other validity issues
* Wrong predictor
* Restriction of range: restrictions in test scores results in lower correlation.

```{r, fig.align="center", asp=1/3, echo=FALSE, eval=FALSE}
x = seq(-4,4,.01)
plot(dnorm(x), type="l", xaxt= "n", yaxt="n", ylab="", xlab="")

```

## Restriction of range

```{r, fig.align="center", asp=1/3, echo=FALSE, warning=FALSE, message=FALSE}
## install.packages("plotly")
library(plotly)

x = rnorm(1000)
y = x + rnorm(1000, 0, 2)

d <- data.frame(x,y)

p <- plot_ly(data = d, x = x, y = y)

p
```


## Increase validity {.subsection}

Criterion validity can be increased by all measures that increase the correlation.

* Higher reliability: more items, deleting bad items
* Use better predictor
* Less restriction of range

## {data-background=../../../topics/test_utility/tile.jpg data-background-size=contain .flexbox .vcenter}

<p style="color:darkblue; font-size:200%; text-align: center;">Just wanting selection<br>to work does not<br>influence the quality<br>of selection</p>

## Problems with selection in NL

* Correlation between predictors and success is low
* We have a bad selection ratio

## Why selection works in US

* High correlation
    * More variation vs NL
    * NL has restriction of range (VWO/HAVO/VMBO) vs high school in US
* Prestigious Ivy League universities have good selection ratio
    * They select very few students; Harvard selects 10% highest SAT
    
## Wrap-up

* Good selection needs high criterion validity
* The higher the correlation the higher the gain
* The efficiency can be determined in advance.
   * When selection is implemented, you can not determine the efficiency
* If criterion validity suffers from restriction of range, then the efficiency argument does not hold.
   * Policy should not be based on psychometric argumentation.
   
